import os
import sys
import asyncio
import base64
import json
import uuid
import random
import boto3
from aws_sdk_bedrock_runtime.client import BedrockRuntimeClient, InvokeModelWithBidirectionalStreamOperationInput
from aws_sdk_bedrock_runtime.models import InvokeModelWithBidirectionalStreamInputChunk, BidirectionalInputPayloadPart
from aws_sdk_bedrock_runtime.config import Config, HTTPAuthSchemeResolver, SigV4AuthScheme
from smithy_aws_core.credentials_resolvers.environment import EnvironmentCredentialsResolver
import langchain_chat_history
import psycopg2
import uuid
from datetime import datetime

# Define a global connection (or manage it however you do for RDS)
pg_conn = None

# Audio config
INPUT_SAMPLE_RATE = 16000
OUTPUT_SAMPLE_RATE = 24000
CHANNELS = 1
CHUNK_SIZE = 1024

session = boto3.Session()
creds = session.get_credentials()
frozen_creds = creds.get_frozen_credentials()

os.environ['AWS_ACCESS_KEY_ID'] = creds.access_key
os.environ['AWS_SECRET_ACCESS_KEY'] = creds.secret_key
os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'
if creds.token:
    os.environ['AWS_SESSION_TOKEN'] = creds.token



def get_pg_connection():
    global pg_conn
    if pg_conn is None or pg_conn.closed:
        pg_conn = psycopg2.connect(
            dbname=os.getenv("PG_DBNAME"),
            user=os.getenv("PG_USER"),
            password=os.getenv("PG_PASSWORD"),
            host=os.getenv("PG_HOST"),
            port=os.getenv("PG_PORT")
        )
    return pg_conn


class NovaSonic:

    def refresh_env_credentials(self):
        global creds, frozen_creds
        # Refresh AWS credentials from the environment
        session = boto3.Session()
        creds = session.get_credentials()
        frozen_creds = creds.get_frozen_credentials()
        
        os.environ['AWS_ACCESS_KEY_ID'] = creds.access_key
        os.environ['AWS_SECRET_ACCESS_KEY'] = creds.secret_key
        if creds.token:
            os.environ['AWS_SESSION_TOKEN'] = creds.token

    def __init__(self, model_id='amazon.nova-sonic-v1:0', region='us-east-1', socket_client=None, voice_id=None, session_id=None):
        self.refresh_env_credentials()
        self.model_id = model_id
        self.region = region
        self.client = None
        self.stream = None
        self.response = None
        self.is_active = False
        self.prompt_name = str(uuid.uuid4())
        self.content_name = str(uuid.uuid4())
        self.audio_content_name = str(uuid.uuid4())
        self.audio_queue = asyncio.Queue()
        self.role = None
        self.display_assistant_text = False  # maybe change later?
        self.voice_id = voice_id  # Store the voice ID passed from frontend
        self.session_id = session_id or os.getenv("SESSION_ID", "default")  # load from env as fallback

    def _init_client(self):
        """Initialize the Bedrock Client for Nova"""
        self.refresh_env_credentials()
        config = Config(
            endpoint_uri=f"https://bedrock-runtime.{self.region}.amazonaws.com",
            region=self.region,
            aws_credentials_identity_resolver=EnvironmentCredentialsResolver(),
            http_auth_scheme_resolver=HTTPAuthSchemeResolver(),
            http_auth_schemes={"aws.auth#sigv4": SigV4AuthScheme()},
        )
        self.client = BedrockRuntimeClient(config=config)
        print(f"Initialized Bedrock client for model {self.model_id} in region {self.region}")

    async def send_event(self, event: dict):
        """
        Given a Python dict, serialize it _without_ leading/trailing
        whitespace and send exactly one JSON object per chunk.
        """
        payload = json.dumps(event, separators=(",", ":"))
        chunk = InvokeModelWithBidirectionalStreamInputChunk(
            value=BidirectionalInputPayloadPart(bytes_=payload.encode("utf-8"))
        )
        await self.stream.input_stream.send(chunk)

    async def start_session(self):
        """Start a new Nova Sonic session"""
        if not self.client:
            self._init_client()

        # Init stream
        self.stream = await self.client.invoke_model_with_bidirectional_stream(
            InvokeModelWithBidirectionalStreamOperationInput(model_id=self.model_id)
        )
        print("‚úÖ Bidirectional stream initialized with Nova Sonic", flush=True)
        print(f"üóÇÔ∏è Using session_id: {self.session_id}", flush=True)
        
        self.is_active = True

        # Send session start event

        # 1) sessionStart
        await self.send_event({
        "event": {
            "sessionStart": {
            "inferenceConfiguration": {
                "maxTokens": 2048,
                "topP": 1.0,
                "temperature": 0.8,
                "stopSequences": []
            }
            }
        }
        })

        
        # Send prompt start event
        voice_ids = {"feminine": ["amy", "tiffany", "lupe"], "masculine": ["matthew", "carlos"]}
        
        # Use the voice ID from frontend if provided, otherwise select a random feminine voice
        selected_voice = self.voice_id if self.voice_id else random.choice(voice_ids['feminine'])
        
        # 2) promptStart
        await self.send_event({
        "event": {
            "promptStart": {
            "promptName": self.prompt_name,
            "textOutputConfiguration": {
                "mediaType": "text/plain"
            },
            "audioOutputConfiguration": {
                "mediaType": "audio/lpcm",
                "sampleRateHertz": 24000,
                "sampleSizeBits": 16,
                "channelCount": 1,
                "voiceId": selected_voice,
                "encoding": "base64",
                "audioType": "SPEECH"
            }
            }
        }
        })


        # 3) SYSTEM contentStart
        await self.send_event({
        "event": {
            "contentStart": {
            "promptName": self.prompt_name,
            "contentName": self.content_name,
            "type": "TEXT",
            "interactive": True,
            "role": "SYSTEM",
            "textInputConfiguration": {
                "mediaType": "text/plain"
            }
            }
        }
        })


        chat_context = langchain_chat_history.format_chat_history(self.session_id)

        system_prompt = f"""{chat_context}
                        You are to act as a concerned patient..."""
        
        # 4) textInput (your system prompt)
        await self.send_event({
        "event": {
            "textInput": {
            "promptName": self.prompt_name,
            "contentName": self.content_name,
            "content": system_prompt
            }
        }
        })


        # 5) contentEnd
        await self.send_event({
        "event": {
            "contentEnd": {
            "promptName": self.prompt_name,
            "contentName": self.content_name
            }
        }
        })


        # Start processing responses
        self.response = asyncio.create_task(self._process_responses())

        print(f"‚úÖ Nova Sonic session started (Prompt ID: {self.prompt_name})", flush=True)
        # at the end of start_session() in nova_sonic.py
        print(json.dumps({ "type": "text", "text": "Nova Sonic ready" }), flush=True)



    async def start_audio_input(self):
        self.audio_content_name = str(uuid.uuid4())
        await self.send_event({
        "event": {
            "contentStart": {
            "promptName": self.prompt_name,
            "contentName": self.audio_content_name,
            "type": "AUDIO",
            "interactive": True,
            "role": "USER",
            "audioInputConfiguration": {
                "mediaType": "audio/lpcm",
                "sampleRateHertz": INPUT_SAMPLE_RATE,
                "sampleSizeBits": 16,
                "channelCount": CHANNELS,
                "audioType": "SPEECH",
                "encoding": "base64"
            }
            }
        }
        })
    
    async def send_audio_chunk(self, audio_bytes):
        blob = base64.b64encode(audio_bytes).decode("utf-8")
        await self.send_event({
        "event": {
            "audioInput": {
            "promptName": self.prompt_name,
            "contentName": self.audio_content_name,
            "content": blob
            }
        }
        })
    
    async def end_audio_input(self):
        await self.send_event({
        "event": {
            "contentEnd": {
            "promptName": self.prompt_name,
            "contentName": self.audio_content_name
            }
        }
        })

    
    async def end_session(self):
        # promptEnd
        await self.send_event({
        "event": {
            "promptEnd": { "promptName": self.prompt_name }
        }
        })
        # sessionEnd
        await self.send_event({
        "event": { "sessionEnd": {} }
        })
        await self.stream.input_stream.close()


    async def _process_responses(self):
        """Process responses from the stream, buffering partial JSON."""
        decoder = json.JSONDecoder()
        buffer = ""  # accumulate incoming text here

        try:
            while self.is_active:
                output = await self.stream.await_output()
                result = await output[1].receive()

                if not (result.value and result.value.bytes_):
                    continue

                # 1) Decode the raw bytes
                chunk = result.value.bytes_.decode("utf-8")
                buffer += chunk

                # 2) Try to peel off as many complete JSON objects as possible
                idx = 0
                while True:
                    try:
                        obj, offset = decoder.raw_decode(buffer[idx:])
                    except json.JSONDecodeError:
                        break
                    idx += offset
                    # 3) Hand off each parsed object
                    await self._handle_event(obj)

                # 4) Keep only the unparsed tail
                buffer = buffer[idx:]

        except Exception as e:
            print(f"üî• Error in _process_responses(): {e}", flush=True)

    async def _handle_event(self, json_data):
        """Dispatch one parsed JSON event to your existing logic."""
        evt = json_data.get("event", {})
        # contentStart
        if "contentStart" in evt:
            content_start = evt["contentStart"]
            self.role = content_start.get("role")
            # optional SPECULATIVE check
            if "additionalModelFields" in content_start:
                fields = json.loads(content_start["additionalModelFields"])
                self.display_assistant_text = (fields.get("generationStage") == "SPECULATIVE")

        # textOutput
        elif "textOutput" in evt:
            text = evt["textOutput"]["content"]
            if self.role == "ASSISTANT":
                print(f"Assistant: {text}", flush=True)
                print(json.dumps({"type": "text", "text": text}), flush=True)
                langchain_chat_history.add_message(self.session_id, "ai", text)
            elif self.role == "USER":
                print(f"User: {text}", flush=True)
                print(json.dumps({"type": "text", "text": text}), flush=True)
                langchain_chat_history.add_message(self.session_id, "user", text)
        
            # Mirror to PostgreSQL
            try:
                conn = get_pg_connection()
                cursor = conn.cursor()
                insert_query = """
                    INSERT INTO messages (message_id, session_id, student_sent, message_content, time_sent)
                    VALUES (%s, %s, %s, %s, %s);
                """
                cursor.execute(insert_query, (
                    str(uuid.uuid4()),
                    self.session_id,
                    True if self.role == "USER" else False,
                    text,
                    datetime.utcnow()
                ))
                conn.commit()
                cursor.close()
            except Exception as e:
                print(f"‚ùå Failed to insert message into PostgreSQL: {e}", flush=True)

        # audioOutput
        elif "audioOutput" in evt:
            b64 = evt["audioOutput"]["content"]
            audio_bytes = base64.b64decode(b64)
            await self.audio_queue.put(audio_bytes)
            print(json.dumps({
                "type": "audio",
                "data": b64,
                "size": len(audio_bytes)
            }), flush=True)

        # else: ignore other event types

async def handle_stdin(nova_client):
    reader = asyncio.StreamReader()
    loop = asyncio.get_event_loop()
    protocol = asyncio.StreamReaderProtocol(reader)
    await loop.connect_read_pipe(lambda: protocol, sys.stdin)

    while True:
        line = await reader.readline()
        if not line:
            break

        try:
            msg = json.loads(line.decode("utf-8"))
            if msg["type"] == "audio":
                print("üé§ Received audio input from stdin", flush=True)
                audio_bytes = base64.b64decode(msg["data"])
                await nova_client.send_audio_chunk(audio_bytes)
            elif msg["type"] == "start_audio":
                print("üé¨ Received start_audio signal", flush=True)
                await nova_client.start_audio_input()
                print("üé§ Started audio input", flush=True)
            elif msg["type"] == "end_audio":
                print("üé¨ Received end_audio signal", flush=True)
                await nova_client.end_audio_input()
            elif msg["type"] == "set_voice":
                voice_id = msg.get("voice_id")
                print(f"üé≠ Received voice change request: {voice_id}", flush=True)
                nova_client.voice_id = voice_id
                print(f"üé≠ Voice set to: {nova_client.voice_id}", flush=True)
                # Force a restart of the session with the new voice
                if nova_client.is_active:
                    print("Restarting session with new voice", flush=True)
                    await nova_client.end_session()
                    await nova_client.start_session()
        except Exception as e:
            print(f"‚ùå Failed to process stdin input: {e}", flush=True)

async def main():
    voice = os.getenv("VOICE_ID")
    session_id = os.getenv("SESSION_ID", "default")
    nova_client = NovaSonic(voice_id=voice, session_id=session_id)
    
    # First listen for any initial configuration from stdin
    # This allows the frontend to set the voice before starting the session
    reader = asyncio.StreamReader()
    loop = asyncio.get_event_loop()
    protocol = asyncio.StreamReaderProtocol(reader)
    await loop.connect_read_pipe(lambda: protocol, sys.stdin)
    
    # Wait for initial configuration for a short time
    try:
        # Set a timeout for initial configuration
        line = await asyncio.wait_for(reader.readline(), 2.0)
        if line:
            try:
                msg = json.loads(line.decode("utf-8"))
                if msg["type"] == "set_voice":
                    print(f"üé≠ Setting initial voice: {msg.get('voice_id')}", flush=True)
                    nova_client.voice_id = msg.get("voice_id")
            except Exception as e:
                print(f"‚ùå Failed to process initial config: {e}", flush=True)
    except asyncio.TimeoutError:
        print("No initial configuration received, using default voice", flush=True)
    
    # Start the session with the configured voice
    await nova_client.start_session()
    print("Nova session started. Listening for stdin input...")
    
    stdin_task = asyncio.create_task(handle_stdin(nova_client))
    await stdin_task

    await nova_client.end_session()
    print("Session ended")

    
if __name__ == "__main__":
    asyncio.run(main())